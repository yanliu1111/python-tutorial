{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanliu1111/python-tutorial/blob/main/Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "Evaluation and benchmarking play a pivotal role in the development of LLM Applications. For optimizing the performance of applications such as RAG (Retrieval Augmented Generation), a robust measurement mechanism is indispensable.\n",
        "\n",
        "LlamaIndex offers vital modules tailored to assess the quality of generated outputs. Additionally, it incorporates specialized modules designed specifically to evaluate content retrieval quality. LlamaIndex categorizes its evaluation into two primary types:\n",
        "\n",
        "*   **Response Evaluation**\n",
        "*   **Retrieval Evaluation**\n",
        "\n",
        "[Documentation\n",
        "](https://gpt-index.readthedocs.io/en/latest/core_modules/supporting_modules/evaluation/root.html)"
      ],
      "metadata": {
        "id": "QYkWSVQDPckV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyxrLlm4V0aZ",
        "outputId": "e95ac41f-f024-4b8f-8732-18727824bc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.8.48-py3-none-any.whl (761 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/761.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/761.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.9/761.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.22)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from llama-index)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting langchain>=0.0.303 (from llama-index)\n",
            "  Downloading langchain-0.0.320-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Collecting openai>=0.26.4 (from llama-index)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting urllib3<2 (from llama-index)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->llama-index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (4.0.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.303->llama-index)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain>=0.0.303->llama-index)\n",
            "  Downloading langsmith-0.0.49-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (2.31.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (1.1.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama-index)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->llama-index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.303->llama-index) (2023.7.22)\n",
            "Installing collected packages: urllib3, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, tiktoken, openai, langsmith, dataclasses-json, langchain, llama-index\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.5.14 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.320 langsmith-0.0.49 llama-index-0.8.48 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.1 tiktoken-0.5.1 typing-inspect-0.9.0 urllib3-1.26.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response Evaluation\n",
        "\n",
        "Evaluating results from LLMs is distinct from traditional machine learning's straightforward outcomes. LlamaIndex employs evaluation modules, using a benchmark LLM like GPT-4, to gauge answer accuracy. Notably, these modules often blend query, context, and response, minimizing the need for ground-truth labels.\n",
        "\n",
        "The evaluation modules manifest in the following categories:\n",
        "\n",
        "*   **Faithfulness:** Assesses whether the response remains true to the retrieved contexts, ensuring there's no distortion or \"hallucination.\"\n",
        "*   **Context Relevancy:** Evaluates the relevance of both the retrieved context and the generated answer to the initial query.\n",
        "*   **Correctness:** Determines if the generated answer aligns with the reference answer based on the query (this does require labels).\n",
        "*   **Guideline Adherence:** Examines whether the predicted answer conforms to specific predefined guidelines.\n",
        "\n",
        "Furthermore, LlamaIndex has the capability to autonomously generate questions from your data, paving the way for an evaluation pipeline to assess the RAG application."
      ],
      "metadata": {
        "id": "oTMyT_qQSH0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# attach to the same event-loop\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "# Set up the root logger\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)  # Set logger level to INFO\n",
        "\n",
        "# Clear out any existing handlers\n",
        "logger.handlers = []\n",
        "\n",
        "# Set up the StreamHandler to output to sys.stdout (Colab's output)\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.INFO)  # Set handler level to INFO\n",
        "\n",
        "# Add the handler to the logger\n",
        "logger.addHandler(handler)"
      ],
      "metadata": {
        "id": "4fTQJZDiZtIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O384ocD_OjDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1470aed9-81cd-4937-dd5b-0fdf5fb417c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index.evaluation import (\n",
        "    DatasetGenerator,\n",
        "    FaithfulnessEvaluator,\n",
        "    RelevancyEvaluator,\n",
        "    CorrectnessEvaluator,\n",
        "    GuidelineEvaluator,\n",
        "    RetrieverEvaluator,\n",
        "    generate_question_context_pairs,\n",
        "    EmbeddingQAFinetuneDataset\n",
        ")\n",
        "\n",
        "from llama_index import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    ServiceContext,\n",
        "    LLMPredictor,\n",
        "    Response,\n",
        ")\n",
        "\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.node_parser import SimpleNodeParser\n",
        "\n",
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "djqOM6UfVzhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download Data"
      ],
      "metadata": {
        "id": "CChQ98mgWGcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7smekBCXWS3X",
        "outputId": "a05e3829-5027-49cf-bf6a-27d359a1970b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-22 07:08:23--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75042 (73K) [text/plain]\n",
            "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
            "\n",
            "\r          data/paul   0%[                    ]       0  --.-KB/s               \rdata/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-10-22 07:08:23 (31.4 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Data"
      ],
      "metadata": {
        "id": "uNfuJB0xXKw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = SimpleDirectoryReader(\"./data/paul_graham/\")\n",
        "documents = reader.load_data()"
      ],
      "metadata": {
        "id": "hIz7x-91VyuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate Question"
      ],
      "metadata": {
        "id": "mVy40TPDXQLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = DatasetGenerator.from_documents(documents)\n",
        "eval_questions = data_generator.generate_questions_from_nodes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iCdPoP8XMY6",
        "outputId": "386cee2b-7c4a-4c12-a726-649960342e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk_size_limit is deprecated, please specify chunk_size instead\n",
            "chunk_size_limit is deprecated, please specify chunk_size instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3756 request_id=41acb325dbfd31ad344019dc88b04aab response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3756 request_id=41acb325dbfd31ad344019dc88b04aab response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4121 request_id=e092e5bd072f375ed60b5114de88724d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4121 request_id=e092e5bd072f375ed60b5114de88724d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3954 request_id=7afb592fa822da304cece34c52ac4348 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3954 request_id=7afb592fa822da304cece34c52ac4348 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4351 request_id=ad766e44b4ec19b4fedc0dcebbca9706 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4351 request_id=ad766e44b4ec19b4fedc0dcebbca9706 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4853 request_id=48c1f6e228025659084e3d950fd9d028 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4853 request_id=48c1f6e228025659084e3d950fd9d028 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5042 request_id=16b9ef2c95c584006eab2ff0dc5052ab response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5042 request_id=16b9ef2c95c584006eab2ff0dc5052ab response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(eval_questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve76lqYJXWF3",
        "outputId": "d46ffb01-bae7-4700-a7f2-03a66c30ded2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What were the two main things the author worked on before college?',\n",
              " 'How did the author describe their early attempts at writing short stories?',\n",
              " 'What type of computer did the author first work with in 9th grade, and what language did they use?',\n",
              " \"What was the author's experience with programming on the IBM 1401?\",\n",
              " \"What type of computer did the author's friend build, and how did the author feel about it?\",\n",
              " \"What type of computer did the author's father eventually buy, and what did the author use it for?\",\n",
              " 'Why did the author decide to switch from studying philosophy to AI in college?',\n",
              " \"What two things influenced the author's interest in working on AI?\",\n",
              " 'What language did the author learn in order to study AI, and why did they choose it?',\n",
              " 'Why did the author decide to focus on Lisp and write a book about Lisp hacking?',\n",
              " 'What was the purpose of the entrance exam for studying art in Florence?',\n",
              " 'How did the author manage to pass the written exam despite their limited vocabulary?',\n",
              " 'What was the arrangement between the students and faculty in the painting department at the Accademia?',\n",
              " \"How did the author's experience painting still lives differ from painting people?\",\n",
              " 'Why did the author enjoy painting still lives?',\n",
              " 'What did the author learn about technology companies during their time at Interleaf?',\n",
              " 'Why did the author decide to drop out of RISD?',\n",
              " 'What is a signature style in the context of painting?',\n",
              " \"How did the author's move to New York impact their financial situation?\",\n",
              " \"What was the author's initial startup idea and why did it not succeed?\",\n",
              " 'What was the initial plan for building online stores in the summer of 1995?',\n",
              " 'How did the idea of running the software on the server and controlling it through the browser come about?',\n",
              " 'What was the name of the new company that was started to build online stores?',\n",
              " 'How did the founders of Viaweb fund their startup initially?',\n",
              " 'What was the main goal of an online store builder according to the author?',\n",
              " 'Why did the author decide to recruit more programmers for Viaweb?',\n",
              " 'How did Viaweb differentiate itself from its competitors in terms of pricing?',\n",
              " 'What did the author learn about retail while building stores for users?',\n",
              " 'What is the ultimate test of a startup according to the author?',\n",
              " 'Why did the author feel relieved when Yahoo bought Viaweb?',\n",
              " \"What was the author's initial excitement when walking past charming little restaurants?\",\n",
              " \"What was the author's idea for a web app and how did they plan to implement it?\",\n",
              " 'Why did the author decide to move to Cambridge and start a new company?',\n",
              " 'Who did the author recruit to work on the new company and what were their roles?',\n",
              " 'What was the name of the new company and what type of company was it?',\n",
              " \"Why did the author decide to build a subset of the company's vision as an open source project?\",\n",
              " \"How did the author's essays gain a wider audience and what did this realization mean for the author?\",\n",
              " 'What was the turning point for the author in realizing what they wanted to work on?',\n",
              " 'How did the author meet Jessica Livingston and what led them to start their own investment firm?',\n",
              " 'What was the unique approach of Y Combinator as an angel firm and how did it differ from traditional VC firms?',\n",
              " 'What was the purpose of the Summer Founders Program mentioned in the context?',\n",
              " 'How did the Summer Founders Program help solve a problem faced by startup founders?',\n",
              " 'What factors contributed to the success of the first batch of startups funded by YC?',\n",
              " 'Why did the author realize that funding startups in batches was a scalable approach?',\n",
              " 'What were some advantages of scale that YC noticed as it grew?',\n",
              " 'Why did the author consider Hacker News to be a source of stress?',\n",
              " 'What advice did Robert Morris give to the author regarding Y Combinator?',\n",
              " 'Why did the author decide to hand over YC to someone else?',\n",
              " 'How did the author spend their time after leaving YC?',\n",
              " \"What was the goal of the author's project to create a new Lisp language called Bel?\",\n",
              " \"How did the author's experience of writing essays impact their ability to understand the code in Bel?\",\n",
              " 'What challenges did the author face while working on Bel, and how did they overcome them?',\n",
              " \"How did the author's move to England affect the development of Bel?\",\n",
              " \"What is the difference between Bel and McCarthy's original Lisp?\",\n",
              " 'Why did the author ban themselves from writing essays while working on Bel?',\n",
              " \"How did the author's intense focus on Bel contribute to their satisfaction with their work?\",\n",
              " \"What role did Twitter and HN (Hacker News) play in the author's perception of their coding efforts?\",\n",
              " \"How did the author's experience of working on Bel while watching their children at the coast impact their perspective on life?\",\n",
              " 'What motivated the author to write essays again after completing Bel?',\n",
              " \"How did the author's experience with Y Combinator influence their approach to funding and supporting startups?\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be consistent we will fix evaluation query"
      ],
      "metadata": {
        "id": "tCNyxGNYgaxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_query = 'How did the author describe their early attempts at writing short stories?'"
      ],
      "metadata": {
        "id": "AABMc2Uxgew_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix GPT-3.5-TURBO LLM for generating response\n",
        "gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "service_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n",
        "\n",
        "# Fix GPT-4 LLM for evaluation\n",
        "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)"
      ],
      "metadata": {
        "id": "2XFysSdSX7pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create vector index\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "    documents, service_context=service_context_gpt35\n",
        ")\n",
        "\n",
        "# Query engine to generate response\n",
        "query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "DWLP0Rk8Yj5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_index.as_retriever(similarity_top_k=3)\n",
        "nodes = retriever.retrieve(eval_query)"
      ],
      "metadata": {
        "id": "fzOT-SiFsABn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(f'<p style=\"font-size:20px\">{nodes[1].get_text()}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "lB9nry-UsMeR",
        "outputId": "f6899061-6a0a-4475-dec8-55112759894d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">What I Worked On\n",
              "\n",
              "February 2021\n",
              "\n",
              "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
              "\n",
              "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n",
              "\n",
              "The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\n",
              "\n",
              "I was puzzled by the 1401. I couldn't figure out what to do with it. And in retrospect there's not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn't have any data stored on punched cards. The only other option was to do things that didn't rely on any input, like calculate approximations of pi, but I didn't know enough math to do anything interesting of that type. So I'm not surprised I can't remember any programs I wrote, because they can't have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn't. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager's expression made clear.\n",
              "\n",
              "With microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\n",
              "\n",
              "The first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\n",
              "\n",
              "Computers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he'd write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\n",
              "\n",
              "Though I liked programming, I didn't plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn't much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\n",
              "\n",
              "I couldn't have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\n",
              "\n",
              "AI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven't tried rereading The Moon is a Harsh Mistress, so I don't know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we'd have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Context Relevency Evaluation\n",
        "\n",
        "Measures if the response + source nodes match the query."
      ],
      "metadata": {
        "id": "8gs6eBCIX2yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RelevancyEvaluator using GPT-4 LLM\n",
        "relevancy_evaluator = RelevancyEvaluator(service_context=service_context_gpt4)"
      ],
      "metadata": {
        "id": "jfTwgJ5SXoeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate response\n",
        "response_vector = query_engine.query(eval_query)\n",
        "\n",
        "# Evaluation\n",
        "eval_result = relevancy_evaluator.evaluate_response(\n",
        "    query=eval_questions[1], response=response_vector\n",
        ")"
      ],
      "metadata": {
        "id": "6Bw9KWY-YflD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5627183-7b79-43c6-e293-34ec8e14969d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=742 request_id=1aff1183a663f21995f321a86e46e4d2 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=742 request_id=1aff1183a663f21995f321a86e46e4d2 response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result.query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3JMGtE-JaQWd",
        "outputId": "3e882b24-8a87-477f-9603-5d38004d892d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How did the author describe their early attempts at writing short stories?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3irb7WZ-cW84",
        "outputId": "62b7395e-ada2-4f5a-eb36-1958e9c1c3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The author described their early attempts at writing short stories as awful. They mentioned that their stories had hardly any plot and mainly focused on characters with strong feelings, which they believed made them deep.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result.passing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBFxnKgXcZlT",
        "outputId": "a42576c5-6e62-47ae-e035-5736b6f96f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relevancy evaluation with multiple source nodes."
      ],
      "metadata": {
        "id": "qaDtmBEjhGQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Query Engine with similarity_top_k=3\n",
        "query_engine = vector_index.as_query_engine(similarity_top_k=3)\n",
        "\n",
        "# Create response\n",
        "response_vector = query_engine.query(eval_query)\n",
        "\n",
        "# Evaluate with each source node\n",
        "eval_source_result_full = [\n",
        "    relevancy_evaluator.evaluate(\n",
        "        query=eval_query,\n",
        "        response=response_vector.response,\n",
        "        contexts=[source_node.get_content()],\n",
        "    )\n",
        "    for source_node in response_vector.source_nodes\n",
        "]\n",
        "\n",
        "# Evaluation result\n",
        "eval_source_result = [\n",
        "    \"Pass\" if result.passing else \"Fail\" for result in eval_source_result_full\n",
        "]"
      ],
      "metadata": {
        "id": "QOhxXsMIgVH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1fdae7-0557-415b-a1b4-343fc03f3a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=829 request_id=3352ca178afa24e5f6eb6b7a36f4f233 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=829 request_id=3352ca178afa24e5f6eb6b7a36f4f233 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=462 request_id=33967e652fcca79bebdf15d748fe8197 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=462 request_id=33967e652fcca79bebdf15d748fe8197 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=766 request_id=30d8b04b721405331943e77f9ba5b746 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=766 request_id=30d8b04b721405331943e77f9ba5b746 response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_source_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-euW1W3VhgPx",
        "outputId": "75451245-a6ec-491a-ec0f-0a36385a4eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Fail', 'Pass', 'Fail']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Faithfullness Evaluator\n",
        "\n",
        " Measures if the response from a query engine matches any source nodes. This is useful for measuring if the response was hallucinated."
      ],
      "metadata": {
        "id": "Rrd_7kufgozj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faithfulness_evaluator = FaithfulnessEvaluator(service_context=service_context_gpt4)"
      ],
      "metadata": {
        "id": "Pb3d08hrclbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = faithfulness_evaluator.evaluate_response(response=response_vector)"
      ],
      "metadata": {
        "id": "hWOKhDVTdm5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d6799d-884d-4ac9-ad93-46f3855b399a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=865 request_id=0f5bc8e43853b5886e8cf965ef25113f response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=865 request_id=0f5bc8e43853b5886e8cf965ef25113f response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH977tlPk6HQ",
        "outputId": "2130e800-ee62-41dc-a386-6009694ebe43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EvaluationResult(query=None, contexts=[\"[10]\\n\\nWow, I thought, there's an audience. If I write something and put it on the web, anyone can read it. That may seem obvious now, but it was surprising then. In the print era there was a narrow channel to readers, guarded by fierce monsters known as editors. The only way to get an audience for anything you wrote was to get it published as a book, or in a newspaper or magazine. Now anyone could publish anything.\\n\\nThis had been possible in principle since 1993, but not many people had realized it yet. I had been intimately involved with building the infrastructure of the web for most of that time, and a writer as well, and it had taken me 8 years to realize it. Even then it took me several years to understand the implications. It meant there would be a whole new generation of essays. [11]\\n\\nIn the print era, the channel for publishing essays had been vanishingly small. Except for a few officially anointed thinkers who went to the right parties in New York, the only people allowed to publish essays were specialists writing about their specialties. There were so many essays that had never been written, because there had been no way to publish them. Now they could be, and I was going to write them. [12]\\n\\nI've worked on several different things, but to the extent there was a turning point where I figured out what to work on, it was when I started publishing essays online. From then on I knew that whatever else I did, I'd always write essays too.\\n\\nI knew that online essays would be a marginal medium at first. Socially they'd seem more like rants posted by nutjobs on their GeoCities sites than the genteel and beautifully typeset compositions published in The New Yorker. But by this point I knew enough to find that encouraging instead of discouraging.\\n\\nOne of the most conspicuous patterns I've noticed in my life is how well it has worked, for me at least, to work on things that weren't prestigious. Still life has always been the least prestigious form of painting. Viaweb and Y Combinator both seemed lame when we started them. I still get the glassy eye from strangers when they ask what I'm writing, and I explain that it's an essay I'm going to publish on my web site. Even Lisp, though prestigious intellectually in something like the way Latin is, also seems about as hip.\\n\\nIt's not that unprestigious types of work are good per se. But when you find yourself drawn to some kind of work despite its current lack of prestige, it's a sign both that there's something real to be discovered there, and that you have the right kind of motives. Impure motives are a big danger for the ambitious. If anything is going to lead you astray, it will be the desire to impress people. So while working on things that aren't prestigious doesn't guarantee you're on the right track, it at least guarantees you're not on the most common type of wrong one.\\n\\nOver the next several years I wrote lots of essays about all kinds of different topics. O'Reilly reprinted a collection of them as a book, called Hackers & Painters after one of the essays in it. I also worked on spam filters, and did some more painting. I used to have dinners for a group of friends every thursday night, which taught me how to cook for groups. And I bought another building in Cambridge, a former candy factory (and later, twas said, porn studio), to use as an office.\\n\\nOne night in October 2003 there was a big party at my house. It was a clever idea of my friend Maria Daniels, who was one of the thursday diners. Three separate hosts would all invite their friends to one party. So for every guest, two thirds of the other guests would be people they didn't know but would probably like. One of the guests was someone I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days later I asked her out.\\n\\nJessica was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders.\\n\\nWhen the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm. It took them weeks to make up their minds, and during this time I started telling her about all the things that needed to be fixed about venture capital.\", 'What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\\n\\nThe first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\\n\\nComputers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he\\'d write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\\n\\nThough I liked programming, I didn\\'t plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn\\'t much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\\n\\nI couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.', 'Not so much because it was badly written as because the problem is so convoluted. When you\\'re working on an interpreter written in itself, it\\'s hard to keep track of what\\'s happening at what level, and errors can be practically encrypted by the time you get them.\\n\\nSo I said no more essays till Bel was done. But I told few people about Bel while I was working on it. So for years it must have seemed that I was doing nothing, when in fact I was working harder than I\\'d ever worked on anything. Occasionally after wrestling for hours with some gruesome bug I\\'d check Twitter or HN and see someone asking \"Does Paul Graham still code?\"\\n\\nWorking on Bel was hard but satisfying. I worked on it so intensively that at any given time I had a decent chunk of the code in my head and could write more there. I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\\n\\nIn the summer of 2016 we moved to England. We wanted our kids to see what it was like living in another country, and since I was a British citizen by birth, that seemed the obvious choice. We only meant to stay for a year, but we liked it so much that we still live there. So most of Bel was written in England.\\n\\nIn the fall of 2019, Bel was finally finished. Like McCarthy\\'s original Lisp, it\\'s a spec rather than an implementation, although like McCarthy\\'s Lisp it\\'s a spec expressed as code.\\n\\nNow that I could write essays again, I wrote a bunch about topics I\\'d had stacked up. I kept writing essays through 2020, but I also started to think about other things I could work on. How should I choose what to do? Well, how had I chosen what to work on in the past? I wrote an essay for myself to answer that question, and I was surprised how long and messy the answer turned out to be. If this surprised me, who\\'d lived it, then I thought perhaps it would be interesting to other people, and encouraging to those with similarly messy lives. So I wrote a more detailed version for others to read, and this is the last sentence of it.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotes\\n\\n[1] My experience skipped a step in the evolution of computers: time-sharing machines with interactive OSes. I went straight from batch processing to microcomputers, which made microcomputers seem all the more exciting.\\n\\n[2] Italian words for abstract concepts can nearly always be predicted from their English cognates (except for occasional traps like polluzione). It\\'s the everyday words that differ. So if you string together a lot of abstract concepts with a few simple verbs, you can make a little Italian go a long way.\\n\\n[3] I lived at Piazza San Felice 4, so my walk to the Accademia went straight down the spine of old Florence: past the Pitti, across the bridge, past Orsanmichele, between the Duomo and the Baptistery, and then up Via Ricasoli to Piazza San Marco. I saw Florence at street level in every possible condition, from empty dark winter evenings to sweltering summer days when the streets were packed with tourists.\\n\\n[4] You can of course paint people like still lives if you want to, and they\\'re willing. That sort of portrait is arguably the apex of still life painting, though the long sitting does tend to produce pained expressions in the sitters.\\n\\n[5] Interleaf was one of many companies that had smart people and built impressive technology, and yet got crushed by Moore\\'s Law. In the 1990s the exponential growth in the power of commodity (i.e. Intel) processors rolled up high-end, special-purpose hardware and software companies like a bulldozer.\\n\\n[6] The signature style seekers at RISD weren\\'t specifically mercenary. In the art world, money and coolness are tightly coupled. Anything expensive comes to be seen as cool, and anything seen as cool will soon become equally expensive.\\n\\n[7] Technically the apartment wasn\\'t rent-controlled but rent-stabilized, but this is a refinement only New Yorkers would know or care about. The point is that it was really cheap, less than half market price.\\n\\n[8] Most software you can launch as soon as it\\'s done. But when the software is an online store builder and you\\'re hosting the stores, if you don\\'t have any users yet, that fact will be painfully obvious.'], response='The author described their early attempts at writing short stories as awful. They mentioned that their stories had hardly any plot and mainly focused on characters with strong feelings, which they believed made the stories deep.', passing=True, feedback='YES', score=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result.passing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsiWpNXHdsoz",
        "outputId": "22f96c8f-3325-4462-91ac-59449c86cd20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correctness Evaluator\n",
        "\n",
        "Evaluates the relevance and correctness of a generated answer against a reference answer."
      ],
      "metadata": {
        "id": "SqsEWzF1i1Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_evaluator = CorrectnessEvaluator(service_context=service_context_gpt4)"
      ],
      "metadata": {
        "id": "ZdX4-K-NfNIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = (\n",
        "    \"Can you explain the theory of relativity proposed by Albert Einstein in detail?\"\n",
        ")\n",
        "\n",
        "reference = \"\"\"\n",
        "Certainly! Albert Einstein's theory of relativity consists of two main components: special relativity and general relativity. Special relativity, published in 1905, introduced the concept that the laws of physics are the same for all non-accelerating observers and that the speed of light in a vacuum is a constant, regardless of the motion of the source or observer. It also gave rise to the famous equation E=mc², which relates energy (E) and mass (m).\n",
        "\n",
        "General relativity, published in 1915, extended these ideas to include the effects of gravity. According to general relativity, gravity is not a force between masses, as described by Newton's theory of gravity, but rather the result of the warping of space and time by mass and energy. Massive objects, such as planets and stars, cause a curvature in spacetime, and smaller objects follow curved paths in response to this curvature. This concept is often illustrated using the analogy of a heavy ball placed on a rubber sheet, causing it to create a depression that other objects (representing smaller masses) naturally move towards.\n",
        "\n",
        "In essence, general relativity provided a new understanding of gravity, explaining phenomena like the bending of light by gravity (gravitational lensing) and the precession of the orbit of Mercury. It has been confirmed through numerous experiments and observations and has become a fundamental theory in modern physics.\n",
        "\"\"\"\n",
        "\n",
        "response = \"\"\"\n",
        "Certainly! Albert Einstein's theory of relativity consists of two main components: special relativity and general relativity. Special relativity, published in 1905, introduced the concept that the laws of physics are the same for all non-accelerating observers and that the speed of light in a vacuum is a constant, regardless of the motion of the source or observer. It also gave rise to the famous equation E=mc², which relates energy (E) and mass (m).\n",
        "\n",
        "However, general relativity, published in 1915, extended these ideas to include the effects of magnetism. According to general relativity, gravity is not a force between masses but rather the result of the warping of space and time by magnetic fields generated by massive objects. Massive objects, such as planets and stars, create magnetic fields that cause a curvature in spacetime, and smaller objects follow curved paths in response to this magnetic curvature. This concept is often illustrated using the analogy of a heavy ball placed on a rubber sheet with magnets underneath, causing it to create a depression that other objects (representing smaller masses) naturally move towards due to magnetic attraction.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pbsExY8qi9ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_result = correctness_evaluator.evaluate(\n",
        "    query=query,\n",
        "    response=response,\n",
        "    reference=reference,\n",
        ")"
      ],
      "metadata": {
        "id": "6fOKYRacjIkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72fd3d91-1c42-4191-cd78-41e883f4fccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7286 request_id=75031a5c27a088643aab3861a3b552ec response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7286 request_id=75031a5c27a088643aab3861a3b552ec response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhEnvJtIjL91",
        "outputId": "be44ffe2-2897-4e05-9bd9-4f0a2d2efefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EvaluationResult(query='Can you explain the theory of relativity proposed by Albert Einstein in detail?', contexts=None, response=\"\\nCertainly! Albert Einstein's theory of relativity consists of two main components: special relativity and general relativity. Special relativity, published in 1905, introduced the concept that the laws of physics are the same for all non-accelerating observers and that the speed of light in a vacuum is a constant, regardless of the motion of the source or observer. It also gave rise to the famous equation E=mc², which relates energy (E) and mass (m).\\n\\nHowever, general relativity, published in 1915, extended these ideas to include the effects of magnetism. According to general relativity, gravity is not a force between masses but rather the result of the warping of space and time by magnetic fields generated by massive objects. Massive objects, such as planets and stars, create magnetic fields that cause a curvature in spacetime, and smaller objects follow curved paths in response to this magnetic curvature. This concept is often illustrated using the analogy of a heavy ball placed on a rubber sheet with magnets underneath, causing it to create a depression that other objects (representing smaller masses) naturally move towards due to magnetic attraction.\\n\", passing=False, feedback=\"The generated answer is relevant to the user query and starts off correctly by explaining the two components of Einstein's theory of relativity: special relativity and general relativity. However, it contains a significant mistake in the explanation of general relativity. The generated answer incorrectly states that general relativity involves the effects of magnetism and that gravity is the result of the warping of space and time by magnetic fields. This is incorrect. In general relativity, gravity is the result of the warping of space and time by mass and energy, not magnetic fields. This error significantly affects the accuracy of the explanation.\", score=2.5)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_result.score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbWAp_krjSCI",
        "outputId": "5b779a93-cf8e-4233-ddc1-565ca5d7647f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_result.passing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBk5I1i9jWM_",
        "outputId": "a07879e8-ab71-4396-9788-bde65f5aa96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correctness_result.feedback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "66aEQczhjXpO",
        "outputId": "cfa3f2e2-e9e5-48a1-f949-0335504b4b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The generated answer is relevant to the user query and starts off correctly by explaining the two components of Einstein's theory of relativity: special relativity and general relativity. However, it contains a significant mistake in the explanation of general relativity. The generated answer incorrectly states that general relativity involves the effects of magnetism and that gravity is the result of the warping of space and time by magnetic fields. This is incorrect. In general relativity, gravity is the result of the warping of space and time by mass and energy, not magnetic fields. This error significantly affects the accuracy of the explanation.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Guideline Evaluator\n",
        "\n",
        "Evaluates a question answer system given user specified guidelines."
      ],
      "metadata": {
        "id": "P7EcLsoVjmZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GUIDELINES = [\n",
        "    \"The response should fully answer the query.\",\n",
        "    \"The response should avoid being vague or ambiguous.\",\n",
        "    \"The response should be specific and use statistics or numbers when possible.\",\n",
        "]"
      ],
      "metadata": {
        "id": "sotyCAmCjZbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluators = [\n",
        "    GuidelineEvaluator(service_context=service_context_gpt4, guidelines=guideline)\n",
        "    for guideline in GUIDELINES\n",
        "]"
      ],
      "metadata": {
        "id": "uzuURTW-jrFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = {\n",
        "    \"query\": \"Tell me about global warming.\",\n",
        "    \"contexts\": [\n",
        "        \"Global warming refers to the long-term increase in Earth's average surface temperature due to human activities such as the burning of fossil fuels and deforestation.\",\n",
        "        \"It is a major environmental issue with consequences such as rising sea levels, extreme weather events, and disruptions to ecosystems.\",\n",
        "        \"Efforts to combat global warming include reducing carbon emissions, transitioning to renewable energy sources, and promoting sustainable practices.\",\n",
        "    ],\n",
        "    \"response\": \"Global warming is a critical environmental issue caused by human activities that lead to a rise in Earth's temperature. It has various adverse effects on the planet.\",\n",
        "}"
      ],
      "metadata": {
        "id": "Vktd6BV3jxSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for guideline, evaluator in zip(GUIDELINES, evaluators):\n",
        "    eval_result = evaluator.evaluate(\n",
        "        query=sample_data[\"query\"],\n",
        "        contexts=sample_data[\"contexts\"],\n",
        "        response=sample_data[\"response\"],\n",
        "    )\n",
        "    print(\"=====\")\n",
        "    print(f\"Guideline: {guideline}\")\n",
        "    print(f\"Pass: {eval_result.passing}\")\n",
        "    print(f\"Feedback: {eval_result.feedback}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKk0jpFwjzp9",
        "outputId": "95148e7e-d2c7-403c-c02d-78ec6cc68dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3059 request_id=0413cfc5f05a74e118b0a8fbe015a530 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3059 request_id=0413cfc5f05a74e118b0a8fbe015a530 response_code=200\n",
            "=====\n",
            "Guideline: The response should fully answer the query.\n",
            "Pass: False\n",
            "Feedback: The response is too brief and does not fully answer the query. It should include more details about the causes, effects, and potential solutions to global warming. It could also mention the scientific consensus on the issue and the role of greenhouse gases.\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2244 request_id=cda1eb90385fef5945202042c2da9aee response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2244 request_id=cda1eb90385fef5945202042c2da9aee response_code=200\n",
            "=====\n",
            "Guideline: The response should avoid being vague or ambiguous.\n",
            "Pass: False\n",
            "Feedback: The response is too vague and does not provide specific details about global warming. It should include more information about the causes, effects, and potential solutions to global warming.\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3262 request_id=4d2be961819d570acc082653c9dd8418 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3262 request_id=4d2be961819d570acc082653c9dd8418 response_code=200\n",
            "=====\n",
            "Guideline: The response should be specific and use statistics or numbers when possible.\n",
            "Pass: False\n",
            "Feedback: The response is too general and lacks specific details or statistics about global warming. It would be more informative to include data such as the rate of temperature increase, the amount of greenhouse gases emitted by human activities, or the projected impacts of global warming.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hit Rate:\n",
        "MRR:\n",
        "\n",
        "Document -> D\n",
        "\n",
        "D -> N1, N2, N3, N4, N5 -> Index/ Retriever\n",
        "\n",
        "(Q1, N1)\n",
        "(Q2, N1)\n",
        "(Q3, N2)\n",
        "(Q4, N2)\n",
        "(Q5, N3)\n",
        "(Q6, N3)\n",
        "(Q7, N4)\n",
        "(Q8, N4)\n",
        "(Q9, N5)\n",
        "(Q10, N5)\n",
        "\n",
        "Q1 -> Index/ Retriever -> N2, N1, N3 -> 1 -> 1/2\n",
        "\n",
        "Q2 -> Index/ Retriever -> N5, N4, N3 -> 0 -> 0\n",
        "\n",
        "Q3 -> Index/ Retriever -> N1, N2, N3 -> 1 -> 1/2\n",
        "\n",
        "Q4 -> Index/ Retriever -> N2, N3, N5 -> 1 -> 1/1\n",
        "\n",
        "Q5 -> Index/ Retriever -> N3, N1, N4 -> 1 -> 1/1\n",
        "\n",
        "Q6 -> Index/ Retriever -> N1, N2, N3 -> 1 -> 1/3\n",
        "\n",
        "Q7 -> Index/ Retriever -> N4, N1, N2 -> 1 -> 1/1\n",
        "\n",
        "Q8 -> Index/ Retriever -> N1, N3, N4 -> 1 -> 1/3\n",
        "\n",
        "Q9 -> Index/ Retriever -> N2, N3, N4 -> 0 -> 0\n",
        "\n",
        "Q10 -> Index/ Retriever -> N2, N5, N3 -> 1 -> 1/2\n",
        "\n",
        "Hit Rate: 8/10 -> 80%\n",
        "\n",
        "MRR: (0.5 + 0 + 0.5 + 1 + 1 + 0.33 + 1 + 0.33 + 0 + 0.5)/10 -> 0.55"
      ],
      "metadata": {
        "id": "qXKPpQ0tP76P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval Evaluation\n",
        "\n",
        "Evaluates the quality of any Retriever module defined in LlamaIndex.\n",
        "\n",
        "To assess the quality of a Retriever module in LlamaIndex, we use metrics like hit-rate and MRR. These compare retrieved results to ground-truth context for any question. For simpler evaluation dataset creation, we utilize synthetic data generation."
      ],
      "metadata": {
        "id": "aX7xg4hAohDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = SimpleDirectoryReader(\"./data/paul_graham/\")\n",
        "documents = reader.load_data()\n",
        "\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "wFtWgxqj1x7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = VectorStoreIndex(nodes, service_context=service_context_gpt4)"
      ],
      "metadata": {
        "id": "L8WLcpA-12LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the retriever\n",
        "retriever = vector_index.as_retriever(similarity_top_k=2)"
      ],
      "metadata": {
        "id": "XZllZ2u5oj0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_nodes = retriever.retrieve(eval_query)"
      ],
      "metadata": {
        "id": "A5R3H3erqx_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.response.notebook_utils import display_source_node\n",
        "\n",
        "for node in retrieved_nodes:\n",
        "    display_source_node(node, source_length=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "VMHGPbUiqned",
        "outputId": "627f7f3c-1835-4484-deec-71a49562d6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 55eaba3d-6090-49cb-9c67-1e7ec1013eae<br>**Similarity:** 0.8270985899550666<br>**Text:** What I Worked On\n\nFebruary 2021\n\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\n\nI was puzzled by the 1401. I couldn't figure out what to do with it. And in retrospect there's not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn't have any data stored on punched cards. The only other option was to do things that didn't rely on any input, like calculate approximations of pi, but I didn't know enough math to do anything interesting of that type. So I'm not surprised I can't remember any programs I wrote, because they can't have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn't. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager's expression made clear.\n\nWith microcomputers, everything changed. Now you could h...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** d5f80634-da74-44e6-af14-f33820e0811f<br>**Similarity:** 0.8202827004437565<br>**Text:** Now they could be, and I was going to write them. [12]\n\nI've worked on several different things, but to the extent there was a turning point where I figured out what to work on, it was when I started publishing essays online. From then on I knew that whatever else I did, I'd always write essays too.\n\nI knew that online essays would be a marginal medium at first. Socially they'd seem more like rants posted by nutjobs on their GeoCities sites than the genteel and beautifully typeset compositions published in The New Yorker. But by this point I knew enough to find that encouraging instead of discouraging.\n\nOne of the most conspicuous patterns I've noticed in my life is how well it has worked, for me at least, to work on things that weren't prestigious. Still life has always been the least prestigious form of painting. Viaweb and Y Combinator both seemed lame when we started them. I still get the glassy eye from strangers when they ask what I'm writing, and I explain that it's an essay I'm going to publish on my web site. Even Lisp, though prestigious intellectually in something like the way Latin is, also seems about as hip.\n\nIt's not that unprestigious types of work are good per se. But when you find yourself drawn to some kind of work despite its current lack of prestige, it's a sign both that there's something real to be discovered there, and that you have the right kind of motives. Impure motives are a big danger for the ambitious. If anything is going to lead you astray, it will be the desire to impress people. So while working on things that aren't prestigious doesn't guarantee you're on the right track, it at least guarantees you're not on the most common type of wrong one.\n\nOver the next several years I wrote lots of essays about all kinds of different topics. O'Reilly reprinted a collection of them as a book, called Hackers & Painters after one of the essays in it. I also worked on spam filters, and did some more painting. I used to have dinners for a group...<br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset = generate_question_context_pairs(nodes, llm=gpt4, num_questions_per_chunk=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2EzD6m_rDU4",
        "outputId": "a2a24a5c-423a-42d4-81c6-4e1f55146a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36/36 [02:33<00:00,  4.26s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = qa_dataset.queries.values()\n",
        "print(list(queries)[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9sidRY0xNz-",
        "outputId": "9a64e306-0d18-41a9-9cdd-5f7bdbdd2a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Discuss the initial investment model of Y Combinator (YC) for startups and explain how it was considered fair for both the investors and the founders.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(queries))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecH5iAUrTaAW",
        "outputId": "2d91a8dc-c51b-4b9e-a605-e5d6f6f4b3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "mm5GCNZoriDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try it out on a sample query\n",
        "sample_id, sample_query = list(qa_dataset.queries.items())[0]\n",
        "sample_expected = qa_dataset.relevant_docs[sample_id]\n",
        "\n",
        "eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb5p06r0xYOR",
        "outputId": "c892a275-d8b4-49d9-9a9b-7070fb21d6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=54 request_id=2c9ff43be0e9c88b4525d99f3a9a4bf0 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=54 request_id=2c9ff43be0e9c88b4525d99f3a9a4bf0 response_code=200\n",
            "Query: In the context, the author mentions his early experiences with programming on an IBM 1401. Describe the process he used to run a program on this machine and explain why he found it challenging to create meaningful programs on it.\n",
            "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try it out on an entire dataset\n",
        "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
      ],
      "metadata": {
        "id": "MF4-RWsDrnMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba821fd-3fbc-41d3-ae1e-0abf65aaeb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=1873150aa2a3f95fa82087cf63342fa8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=1873150aa2a3f95fa82087cf63342fa8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=8199a2d93b57c86a7eb3238ed1685a59 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=8199a2d93b57c86a7eb3238ed1685a59 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=45 request_id=7da0dba1da5c24046a42a03e7063ca28 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=45 request_id=7da0dba1da5c24046a42a03e7063ca28 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=76 request_id=7185da7320e7c4ad8ab05274d8c8978e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=76 request_id=7185da7320e7c4ad8ab05274d8c8978e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=72c066502c9cdda7ea97267c0c8ec8bf response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=72c066502c9cdda7ea97267c0c8ec8bf response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=87 request_id=91d4170fc7f625c3eb0164a8b5d79a42 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=87 request_id=91d4170fc7f625c3eb0164a8b5d79a42 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=34 request_id=61f3c6e6720c66bdd53dfca34cc8c4c0 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=34 request_id=61f3c6e6720c66bdd53dfca34cc8c4c0 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=56 request_id=eab2b4ae0e0f562be90d3b7555ddb74d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=56 request_id=eab2b4ae0e0f562be90d3b7555ddb74d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=30 request_id=03eefc5e5cfc9fa4da9e4f6603041289 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=30 request_id=03eefc5e5cfc9fa4da9e4f6603041289 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=7f2f89aa3846432d4f238b0c93c01860 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=7f2f89aa3846432d4f238b0c93c01860 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=95e1e9d8b6f5861cd0ae9281908e03d8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=95e1e9d8b6f5861cd0ae9281908e03d8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=36 request_id=2360f2dcec9987437aba6dcd8bd319ec response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=36 request_id=2360f2dcec9987437aba6dcd8bd319ec response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=06273341ec10fde6dce9e7a2db2605dd response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=06273341ec10fde6dce9e7a2db2605dd response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=56 request_id=146642e70c634da0a7aa8b1eec2c01c6 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=56 request_id=146642e70c634da0a7aa8b1eec2c01c6 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=c4d71d00196c6dc52c179d21843afe69 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=c4d71d00196c6dc52c179d21843afe69 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=9627acd715b16d8d92004953f984d5a1 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=9627acd715b16d8d92004953f984d5a1 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=33 request_id=6ff601097a81639ca9c4aa00a7469230 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=33 request_id=6ff601097a81639ca9c4aa00a7469230 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=40 request_id=33dee7b81939644917f06a7c6d5ee050 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=40 request_id=33dee7b81939644917f06a7c6d5ee050 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=25 request_id=02d36aaf7022b100486c6e0b94d856b8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=25 request_id=02d36aaf7022b100486c6e0b94d856b8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=32 request_id=f4965c748cac0d5fd5d2bb4a83ad1b42 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=32 request_id=f4965c748cac0d5fd5d2bb4a83ad1b42 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=17428d7e15d4306b01bd8d88a7c6fba7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=17428d7e15d4306b01bd8d88a7c6fba7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=032a51071c9af11d087d974c77f37915 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=032a51071c9af11d087d974c77f37915 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=25 request_id=c7da731ab2e7bb528523e92a2e6e5a39 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=25 request_id=c7da731ab2e7bb528523e92a2e6e5a39 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=1c45b46b0f727b20a31a8a371f5c4b12 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=1c45b46b0f727b20a31a8a371f5c4b12 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=33 request_id=169f558d8ca9b6c3d4909a0520b61ac7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=33 request_id=169f558d8ca9b6c3d4909a0520b61ac7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=25 request_id=070245c1ee1621ae752c6815dadcb0d8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=25 request_id=070245c1ee1621ae752c6815dadcb0d8 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=b37bd3ded211dc30dbe6fa2aa86e3f7f response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=b37bd3ded211dc30dbe6fa2aa86e3f7f response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=aeb0b29834e23bf4887ec9a15e7e2204 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=aeb0b29834e23bf4887ec9a15e7e2204 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=47ccecd918ec847ecf0586554f426c07 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=47ccecd918ec847ecf0586554f426c07 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=36 request_id=4e34a070925f92721384820e14fd9283 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=36 request_id=4e34a070925f92721384820e14fd9283 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=27 request_id=fb0a9228071bad779e998e9839d793d0 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=27 request_id=fb0a9228071bad779e998e9839d793d0 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=fb6bedcd83aae9ca9ad0583ea8b7020e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=fb6bedcd83aae9ca9ad0583ea8b7020e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=7fee6012b07db2653d16370630564e1d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=7fee6012b07db2653d16370630564e1d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=29 request_id=d6f021f27d3c5ca69d2790009552f1bd response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=29 request_id=d6f021f27d3c5ca69d2790009552f1bd response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=b1a5fd83b3d5f72cdca5050945626cbe response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=19 request_id=b1a5fd83b3d5f72cdca5050945626cbe response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=fb1544352715ba6313a078203d7ed083 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=35 request_id=fb1544352715ba6313a078203d7ed083 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=cf68a19f2d34a79bf890ba2ce5b31b94 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=cf68a19f2d34a79bf890ba2ce5b31b94 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=53 request_id=b4f8cf860031e665729fe090a6a47f36 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=53 request_id=b4f8cf860031e665729fe090a6a47f36 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=33 request_id=c6648a0de7d13388c23d50cb07dcf07a response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=33 request_id=c6648a0de7d13388c23d50cb07dcf07a response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=24 request_id=60856ad411da15c8dcec55c996f49b30 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=24 request_id=60856ad411da15c8dcec55c996f49b30 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=29 request_id=be324c43d716a30c054ba42b5147beaa response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=29 request_id=be324c43d716a30c054ba42b5147beaa response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=26 request_id=6bf5b0dcae8bfe1d3e266b2753235b9e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=26 request_id=6bf5b0dcae8bfe1d3e266b2753235b9e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=6eaa3c8fce6da7931a530006fd15f0c1 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=6eaa3c8fce6da7931a530006fd15f0c1 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=5db962fe501452ae84b2633741886169 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=5db962fe501452ae84b2633741886169 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=28 request_id=a3732ac19f8493c04fab2aeddbd235ac response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=28 request_id=a3732ac19f8493c04fab2aeddbd235ac response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=34 request_id=8e7e15e7d124f1b7f24d78f0162aa03d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=34 request_id=8e7e15e7d124f1b7f24d78f0162aa03d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=6328bfd2cae8d8bcdccb80407d9c482d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=6328bfd2cae8d8bcdccb80407d9c482d response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=27 request_id=1522a44d7f9fdedff93c821d287dcf63 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=27 request_id=1522a44d7f9fdedff93c821d287dcf63 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=50 request_id=846e08af4fdfdfbc17a0f6d2c0dd7323 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=50 request_id=846e08af4fdfdfbc17a0f6d2c0dd7323 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=9bc15f09c7fe903b6559081d076b16c9 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=9bc15f09c7fe903b6559081d076b16c9 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=9294744d42b78d759881e14167b3fafa response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=9294744d42b78d759881e14167b3fafa response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=bfb8dd4079edefff0c2d2b227c3e7446 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=bfb8dd4079edefff0c2d2b227c3e7446 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=41 request_id=c263d47240e4096994af8e844dfd6da9 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=41 request_id=c263d47240e4096994af8e844dfd6da9 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=34 request_id=42423857bfa6b9b36cc573f606435769 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=34 request_id=42423857bfa6b9b36cc573f606435769 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=4438f6660771994da6308a698ee6ff2e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=4438f6660771994da6308a698ee6ff2e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=b0d97d6a7fb57c6aa797b70a16a75aa7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=b0d97d6a7fb57c6aa797b70a16a75aa7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=50 request_id=7c20cfd6ab1d38861f1bc3564cc47f95 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=50 request_id=7c20cfd6ab1d38861f1bc3564cc47f95 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=117 request_id=95adffeddde6128e05af960b5ffef499 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=117 request_id=95adffeddde6128e05af960b5ffef499 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=38358af151a37ac00213151afd048d4e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=38358af151a37ac00213151afd048d4e response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=5948ff75869f4b15d243e62335180d54 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=5948ff75869f4b15d243e62335180d54 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=70a79598c300339a64772c1c80450dcc response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=70a79598c300339a64772c1c80450dcc response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=b52daf5688dcc8d8b14dab08cedd8a83 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=17 request_id=b52daf5688dcc8d8b14dab08cedd8a83 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=db475b651dd7b9357b1ce9a0e7db63a5 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=db475b651dd7b9357b1ce9a0e7db63a5 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=2451187cdd9ff3aa1504d01e6e189793 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=2451187cdd9ff3aa1504d01e6e189793 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=29 request_id=4761294e9bc27cc635815ae0f4caf7b5 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=29 request_id=4761294e9bc27cc635815ae0f4caf7b5 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=46 request_id=0c63b3ff0a6bb7dc0bfcd2cb5506c908 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=46 request_id=0c63b3ff0a6bb7dc0bfcd2cb5506c908 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=24 request_id=0067015356671e816a84d98fd11b0fd7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=24 request_id=0067015356671e816a84d98fd11b0fd7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=515cfc83acbdd333b44af160f4acef20 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=515cfc83acbdd333b44af160f4acef20 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=30 request_id=17d8e89b94adf2c78132a97e7e5b2d78 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=30 request_id=17d8e89b94adf2c78132a97e7e5b2d78 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=49d90a9f599a7ad4a6b6995f6012b53a response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=20 request_id=49d90a9f599a7ad4a6b6995f6012b53a response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=26 request_id=2751a758e5d0d9fbe13ab116449cb305 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=26 request_id=2751a758e5d0d9fbe13ab116449cb305 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=fec4f0e8b52df6358454be2d47c0db7b response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=fec4f0e8b52df6358454be2d47c0db7b response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(name, eval_results):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    metric_dicts = []\n",
        "    for eval_result in eval_results:\n",
        "        metric_dict = eval_result.metric_vals_dict\n",
        "        metric_dicts.append(metric_dict)\n",
        "\n",
        "    full_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "    hit_rate = full_df[\"hit_rate\"].mean()\n",
        "    mrr = full_df[\"mrr\"].mean()\n",
        "\n",
        "    metric_df = pd.DataFrame(\n",
        "        {\"retrievers\": [name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}\n",
        "    )\n",
        "\n",
        "    return metric_df"
      ],
      "metadata": {
        "id": "mxiNl6TurpZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_results(\"top-2 eval\", eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yZeIaMWKrsY1",
        "outputId": "df15cff3-493b-4c80-e9fb-28c09ffe2bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   retrievers  hit_rate       mrr\n",
              "0  top-2 eval  0.847222  0.784722"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ae7e768-78fc-4ec9-a2ae-901f5de86528\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>retrievers</th>\n",
              "      <th>hit_rate</th>\n",
              "      <th>mrr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>top-2 eval</td>\n",
              "      <td>0.847222</td>\n",
              "      <td>0.784722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ae7e768-78fc-4ec9-a2ae-901f5de86528')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ae7e768-78fc-4ec9-a2ae-901f5de86528 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ae7e768-78fc-4ec9-a2ae-901f5de86528');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HI3ffLaawktO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}