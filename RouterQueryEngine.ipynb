{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanliu1111/python-tutorial/blob/main/RouterQueryEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Router Query Engine"
      ],
      "metadata": {
        "id": "D1Y3gSVdHdzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we will be using a router query engine, which will choose one of multiple candidate query engines to execute user query.\n",
        "\n",
        "[Documentation](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/RouterQueryEngine.html)"
      ],
      "metadata": {
        "id": "fuAwUKiCCkze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "vlLzNfQrC54i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOZ6iXTJHlQ5",
        "outputId": "6e5b7f5f-2f9c-4d6a-ea69-d75af0cec887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.8.36-py3-none-any.whl (846 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.5/846.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from llama-index)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting langchain>=0.0.293 (from llama-index)\n",
            "  Downloading langchain-0.0.304-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Collecting openai>=0.26.4 (from llama-index)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Collecting urllib3<2 (from llama-index)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.11.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.7)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.293->llama-index) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.293->llama-index) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.293->llama-index) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.293->llama-index) (4.0.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.293->llama-index)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.38 (from langchain>=0.0.293->llama-index)\n",
            "  Downloading langsmith-0.0.41-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.293->llama-index) (2.8.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.293->llama-index) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.293->llama-index) (2.31.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.66.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index) (2.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama-index) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.293->llama-index) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.293->llama-index) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.293->llama-index) (1.1.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.293->llama-index)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.293->llama-index) (2023.7.22)\n",
            "Installing collected packages: urllib3, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, tiktoken, openai, langsmith, dataclasses-json, langchain, llama-index\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.304 langsmith-0.0.41 llama-index-0.8.36 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.1 tiktoken-0.5.1 typing-inspect-0.9.0 urllib3-1.26.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: This is ONLY necessary in jupyter notebook.\n",
        "# Details: Jupyter runs an event-loop behind the scenes.\n",
        "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
        "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "R_Ttz5WDI8M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGEOh3sdFuQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12cb1297-3608-4e3c-8987-b44e21cf6490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:24: UserWarning: Importing BasePromptTemplate from langchain root module is no longer supported.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:24: UserWarning: Importing PromptTemplate from langchain root module is no longer supported.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().handlers = []\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    ListIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        ")\n",
        "\n",
        "import openai\n",
        "openai.api_key = 'YOUR OPENAI KEY'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "igDWYnajC_tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ePCxRKDIXl",
        "outputId": "a68aad2b-bf6e-4996-efe4-01e93a28aaae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-29 03:59:14--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75047 (73K) [text/plain]\n",
            "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
            "\n",
            "\r          data/paul   0%[                    ]       0  --.-KB/s               \rdata/paul_graham/pa 100%[===================>]  73.29K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-09-29 03:59:14 (25.0 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75047/75047]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "l0Cp38vaDGbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
      ],
      "metadata": {
        "id": "7UuQpLoRD1Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define List Index and Vector Index over Same Data"
      ],
      "metadata": {
        "id": "e4LNrmhrK4xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_index = SummaryIndex.from_documents(documents)\n",
        "vector_index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "B9C2Gm1UF8r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2626cc63-ecab-4bdc-a2fa-b0ede6f6628a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Query Engines and Set Metadata"
      ],
      "metadata": {
        "id": "voktqsQNLApj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "uLMKbMAUGA9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.tools.query_engine import QueryEngineTool\n",
        "\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=\"Useful for summarization questions related to Paul Graham eassy on What I Worked On.\",\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=\"Useful for retrieving specific context from Paul Graham essay on What I Worked On.\",\n",
        ")"
      ],
      "metadata": {
        "id": "fg4aOwPaGNxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Router Query Engine\n",
        "\n",
        "There are several selectors available, each with some distinct attributes.\n",
        "\n",
        "The LLM selectors use the LLM to output a JSON that is parsed, and the corresponding indexes are queried.\n",
        "\n",
        "The Pydantic selectors (currently only supported by gpt-4-0613 and gpt-3.5-turbo-0613 (the default)) use the OpenAI Function Call API to produce pydantic selection objects, rather than parsing raw JSON.\n",
        "\n",
        "For each type of selector, there is also the option to select 1 index to route to, or multiple."
      ],
      "metadata": {
        "id": "F0zHAQS_LF3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PydanticSingleSelector"
      ],
      "metadata": {
        "id": "jTncjEj2LH88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.selectors.llm_selectors import LLMSingleSelector\n",
        "from llama_index.selectors.pydantic_selectors import (\n",
        "    PydanticSingleSelector,\n",
        ")\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=PydanticSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "GGjl2y5QGRcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")"
      ],
      "metadata": {
        "id": "0hywia-DGTx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "sriu-0zoLR7q",
        "outputId": "9ac6723d-1fa2-443f-ed12-3db12bf09914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The document provides a personal account of the author's experiences and interests in writing, programming, and art. It discusses their early experiences in writing and programming, their fascination with artificial intelligence, and their decision to focus on Lisp programming. The document also covers their experience in graduate school, their pursuit of both computer science and art, and their eventual decision to attend art school. It highlights their interest in painting still lives and their observations about visual perception. The document also discusses the author's transition into the world of technology and entrepreneurship, their founding of a software company called Viaweb, and the development of their web-based store builder software. It reflects on the importance of high production values in online stores and the value of independence in the people the author worked with. The document also covers the challenges and successes of building an online store builder, the author's experience of being acquired by Yahoo, and their decision to leave and pursue other interests. It discusses the author's realization of the power of publishing on the web, their involvement in various projects, and their decision to start a new company. The document also reflects on the author's exploration of painting, their commitment to writing essays, and their personal experiences that led to their decision to leave Y Combinator. Overall, the document provides a narrative of the author's career journey and the choices they have made.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLMSingleSelector"
      ],
      "metadata": {
        "id": "5zkEOzNYLUQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        list_tool,\n",
        "        summary_tool,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "TbnqXGG-Ga3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")"
      ],
      "metadata": {
        "id": "d_xrq9gYGdf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "ksusZylqG_Nb",
        "outputId": "4e47b2db-6ac1-412e-b8c9-1ae5636ab3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The document provides a personal account of the author's experiences and interests in writing, programming, and art. It starts with their early experiences in writing short stories and programming on an IBM 1401 computer. They then discuss their transition to microcomputers and their fascination with artificial intelligence (AI). However, they eventually realize the limitations of AI and shift their focus to Lisp programming. The author also shares their decision to pursue art and their experiences at art school. The document concludes with the author's exploration of still life painting. The document also discusses the author's involvement in building the infrastructure of the web and their decision to start publishing essays online. It mentions the founding of Y Combinator, an investment firm, and the development of the Summer Founders Program. The author reflects on the growth and success of Y Combinator and the challenges they faced, particularly with Hacker News. The document concludes with the author's decision to leave Y Combinator and their personal experiences that led to this decision. Additionally, the document discusses the creation and development of a software company called Viaweb, which was later acquired by Yahoo. It highlights the challenges and successes of building an online store builder, the importance of high production values in creating a legitimate online presence, the role of art in the design process, the recruitment of talented programmers, the early days of ecommerce, the different parts of the software, the pricing strategy, the unconventional methods used to attract users, the lessons learned about retail, the growth rate of the company, the stress of running a startup, the decision to sell to Yahoo, the author's transition to a new phase of life, the idea for a new web app, the decision to start a new company, the challenges of running a company, the decision to switch to an open source project, the development of a new Lisp dialect called Arc, the author's realization of the power of the internet for publishing essays, and the author's commitment to writing essays. The document also discusses the author's work on developing a new programming language called Bel, their move to England, and the challenges they faced while working on Bel. The document concludes with the author reflecting on their past choices and contemplating future endeavors.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What did Paul Graham do after RICS?\")"
      ],
      "metadata": {
        "id": "IEfQDl8LGd8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "S1DXw_KxHApd",
        "outputId": "7c5c5329-262c-4067-a695-56c44f956b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">After RICS, Paul Graham applied to art schools and was accepted into the BFA program at RISD. He then went on to attend art classes at Harvard and eventually became an artist.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vCZzlGNRHBIi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}